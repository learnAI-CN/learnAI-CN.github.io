# 池化层的反向传播

现在我们讨论一下池化层怎么反向传播

## 平均池化的反向传播

我们定义在正向时，如果输入x中\( m*n \)的尺寸内的值经过平均得到输出y。反向传播时，y处的梯度\( \frac{dl}{dy} \) 平均的分配\( m*n \)的每个值。用公式表示为

$$ \frac{dl}{dx} =  \frac{1}{mn} * \frac{dl}{dy}  $$

池化层的反向传播并不需要额外的参数更新，它只是将梯度传递给前一层，用于更新前一层的参数。

均值池化反向传播的示意图如下所示:

[//]: # (![]&#40;../../img/02/09/02/meanBP.jpg&#41;)
<img alt="mean pooling BP" src="../../../img/02/09/02/meanBP.jpg" class="img-center" width="50%" />


## 最大池化的反向传播

我们定义在正向时，如果输入x中m*n的尺寸内的值经过计算最大值得到输出y。反向传播时，y处的梯度\( \frac{dl}{dy} \) 直接赋给最大值所在的位置。其他地方梯度置0，用公式表示为

- 如果是最大值所在位置: $$ \frac{dl}{dx} = \frac{dl}{dy}  $$
- 如果不是最大值所在位置: $$ \frac{dl}{dx} = 0  $$

为实现上述功能，在前向传播时框架会记住最大值神经元所处的位置坐标。
同样，最大池化层的反向传播并不需要额外的参数更新，它只是将梯度传递给前一层，用于更新前一层的参数。

这时候就有个问题了，如果最大池化的输入m*n中最大值不知一个怎么办？假如有n个相同的最大值，则反向传播时梯度平均除以n，其他地方依旧为0。公式表示如下：

- 如果是n个最大值所在位置: $$ \frac{dl}{dx} = \frac{dl}{dy} / n  $$
- 如果不是最大值所在位置: $$ \frac{dl}{dx} = 0  $$


最大池化反向传播的示意图如下所示:

[//]: # (![]&#40;../../img/02/09/02/maxBP.jpg&#41;)
<img alt="max pooling BP" src="../../../img/02/09/02/maxBP.jpg" class="img-center" width="50%" />


图中蓝色即表示包含相同最大值的情况。但一般计算机中很少出现完全相同的值，所以这种情况不常见。


