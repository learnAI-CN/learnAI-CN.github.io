<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="http://learnopengl.com 系列教程的简体中文翻译">
        
        <link rel="canonical" href="https://learnopengl-cn.github.io/03%20Model%20Loading/04%20ResNet/">
        <link rel="shortcut icon" href="../../img/favicon.ico">

	<title>ResNet - LearnOpenGL CN</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/style.css" rel="stylesheet">
        <link href="../../css/admonition_fix.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-80323542-1', 'auto');
          ga('send', 'pageview');
        </script>
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="../..">LearnOpenGL CN</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
                <li >
                    <a href="../..">主页</a>
                </li>
            
            
            
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">目录 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
<li >
    <a href="../../intro/">简介</a>
</li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">入门</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../01%20Getting%20started/01%20OpenGL/">深度学习介绍</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/Perceptron/">感知机</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/03%20Hello%20Window/">异或操作</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/04%20Hello%20Triangle/">s型神经元</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/05%20Shaders/">损失函数</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/06%20Textures/">反向传播算法</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/07%20Gradient%20vanishing/">梯度消失/爆炸</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/08%20Transformations/">自学习异或操作</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">实现minist</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../02 Lighting/1Channel minist.md">minist一维实现</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/01%20Colors/">卷积层</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/02%20Basic%20Lighting/">池化层</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/03%20Materials/">激活层</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/04%20Lighting%20maps/">全连接层</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/05%20Light%20casters/">优化函数</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/06%20Multiple%20lights/">归一化层</a>
</li>

        
            
<li >
    <a href="../../02%20Lighting/07%20Review/">实现minist识别</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">经典神经网络</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../01%20Assimp/">AlexNet</a>
</li>

        
            
<li >
    <a href="../02%20Mesh/">VGG</a>
</li>

        
            
<li >
    <a href="../03%20Model/">GoogLeNet</a>
</li>

        
            
<li class="active">
    <a href="./">ResNet</a>
</li>

        
            
<li >
    <a href="../05%20DenseNet/">DenseNet</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">高级OpenGL</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/01%20Depth%20testing/">深度测试</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/02%20Stencil%20testing/">模板测试</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/03%20Blending/">混合</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/04%20Face%20culling/">面剔除</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/05%20Framebuffers/">帧缓冲</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/06%20Cubemaps/">立方体贴图</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/07%20Advanced%20Data/">高级数据</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/08%20Advanced%20GLSL/">高级GLSL</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/09%20Geometry%20Shader/">几何着色器</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/10%20Instancing/">实例化</a>
</li>

        
            
<li >
    <a href="../../04%20Advanced%20OpenGL/11%20Anti%20Aliasing/">抗锯齿</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">高级光照</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../05%20Advanced%20Lighting/01%20Advanced%20Lighting/">高级光照</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/02%20Gamma%20Correction/">Gamma校正</a>
</li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">阴影</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../05%20Advanced%20Lighting/03%20Shadows/01%20Shadow%20Mapping/">阴影映射</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/03%20Shadows/02%20Point%20Shadows/">点阴影</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/03%20Shadows/03%20CSM/">CSM</a>
</li>

        
    </ul>
  </li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/04%20Normal%20Mapping/">法线贴图</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/05%20Parallax%20Mapping/">视差贴图</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/06%20HDR/">HDR</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/07%20Bloom/">泛光</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/08%20Deferred%20Shading/">延迟着色法</a>
</li>

        
            
<li >
    <a href="../../05%20Advanced%20Lighting/09%20SSAO/">SSAO</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">PBR</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../07%20PBR/01%20Theory/">理论</a>
</li>

        
            
<li >
    <a href="../../07%20PBR/02%20Lighting/">光照</a>
</li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">IBL</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../07%20PBR/03%20IBL/01%20Diffuse%20irradiance/">漫反射辐照</a>
</li>

        
            
<li >
    <a href="../../07%20PBR/03%20IBL/02%20Specular%20IBL/">镜面IBL</a>
</li>

        
    </ul>
  </li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">实战</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06%20In%20Practice/01%20Debugging/">调试</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/02%20Text%20Rendering/">文本渲染</a>
</li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">2D游戏</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/01%20Breakout/">Breakout</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/02%20Setting%20up/">准备工作</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/03%20Rendering%20Sprites/">渲染精灵</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/04%20Levels/">关卡</a>
</li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">碰撞</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/05%20Collisions/01%20Ball/">球</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/05%20Collisions/02%20Collision%20detection/">碰撞检测</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/05%20Collisions/03%20Collision%20resolution/">碰撞处理</a>
</li>

        
    </ul>
  </li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/06%20Particles/">粒子</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/07%20Postprocessing/">后期处理</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/08%20Powerups/">道具</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/09%20Audio/">音效</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/10%20Render%20Text/">渲染文本</a>
</li>

        
            
<li >
    <a href="../../06%20In%20Practice/2D-Game/11%20Final%20thoughts/">结语</a>
</li>

        
    </ul>
  </li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">Guest Articles</a>
    <ul class="dropdown-menu">
        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">2020</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../08%20Guest%20Articles/2020/01%20Skeletal%20Animation/">骨骼动画</a>
</li>

        
    </ul>
  </li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">2022</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../08%20Guest%20Articles/2022/03%20Area%20Lights/">区域光</a>
</li>

        
    </ul>
  </li>

        
    </ul>
  </li>

                    
                        
<li >
    <a href="../../legacy/">历史存档</a>
</li>

                    
                    </ul>
                </li>
            
            
            
                <li >
                    <a href="../../code_repo/">代码仓库</a>
                </li>
            
            
            </ul>

            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> 搜索
                    </a>
                </li>
                <li >
                    <a rel="next" href="../03%20Model/">
                        <i class="fa fa-arrow-left"></i> 上一节
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../05%20DenseNet/">
                        下一节 <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                <li>
                    <a href="https://github.com/LearnOpenGL-CN/LearnOpenGL-CN">
                        
                            <i class="fa fa-github"></i>
                        
                        GitHub
                    </a>
                </li>
                
                <li>
                    <a href="https://www.paypal.me/learnopengl/">
                            <img class="paypal" src="/img/paypal_logo.png" alt="">
                        支持原作者
                    </a>
                </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#resnet">ResNet</a></li>
        
            <li><a href="#resnet_1">ResNet特点</a></li>
        
            <li><a href="#resnet_2">ResNet引入</a></li>
        
            <li><a href="#_1">退化问题</a></li>
        
            <li><a href="#_2">残差连接</a></li>
        
            <li><a href="#_3">网络结构</a></li>
        
            <li><a href="#_4">代码实现</a></li>
        
            <li><a href="#_5">讨论</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="resnet">ResNet</h1>
<p>ResNet（Residual Network）是由微软亚洲研究院的何凯明等人于2015年提出的一种深度卷积神经网络模型，是目前最为流行和广泛应用的卷积神经网络之一。
ResNet的主要贡献在于提出了残差学习的思路，可以解决深度卷积神经网络中的梯度消失和模型退化等问题，从而实现了更深的网络结构和更好的性能表现。</p>
<h2 id="resnet_1">ResNet特点</h2>
<ul>
<li>提出残差学习</li>
</ul>
<h2 id="resnet_2">ResNet引入</h2>
<p>终于来到了大名鼎鼎的ResNet，这是一篇无论是什么时候去读都不嫌晚，读多少遍都不觉多的经典论文。我希望能尽可能详细的向您讲解该论文。</p>
<p>在之前的网络设计中可以发现网络的深度至关重要。深度网络自然地将低/中/高级特征和分类器以端到端多层方式进行集成，特征的“级别”可以通过堆叠层的数量（深度）来丰富。
如此来说提升网络的性能的唯一障碍就是训练时会遇到的梯度消失/爆炸问题。而这个问题通过标准初始化和BN在很大程度上已经解决，这使得数十层的网络能通过具有反向传播的随机梯度下降（SGD）开始收敛。
网络设计岂不是至此可以高枕无忧了，只需要增加网络层数就可以。但本文发现当网络层数上升时，性能并没有增加。</p>
<h2 id="_1">退化问题</h2>
<p>作者在实验中发现了两个现象。1）随着网络深度的增加，准确率达到饱和然后迅速下降。但这种下降不是由过拟合引起的。
2）在适当的深度模型上添加更多的层会导致更高的训练误差。这两个现象被称为退化问题，实验过程可以如下图表示</p>
<p><img alt="" src="../../img/03/04/tuihua.jpg" /></p>
<p>首先来解释一下第一个问题，第一个问题提到的「准确率迅速下降」并非图中某条准确率曲线的突然下降。而是说单独的网络层数与准确率的关系，就类似于下图。</p>
<p><img alt="" src="../../img/03/04/tuihua1.png" /></p>
<p>这张图是我随便做的层数-准确率的关系图，数据并不精准，只是形象的表述作者的意思。横轴为层数，纵轴为准确率。关键是作者说这种下降并非过拟合引起的。</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>过拟合，是指网络参数太多的情况下，拟合能力太强导致的训练准确率提升，测试准确率降低的情况。</p>
</div>
<p>再来说一下第二个问题，增加网络层数反而训练loss降低。这是挺奇怪的问题，因为56层的拟合能力必然比20层高，如果20层的网络存在最优拟合选项，
那56层网络必然能够训练出相同的拟合效果，为何准确率反而降低了？即使以最极端的情况，添加的层是恒等映射，其他层是从学习到的较浅模型的拷贝。
但为什么实验不符合预期呢？说明网络很难使用多个非线性层来近似恒等映射。</p>
<h2 id="_2">残差连接</h2>
<p>那我们就自己设计一个连接学习恒等映射。所以作者通过引入深度残差学习框架解决了退化问题。 如下图所示,原来我们希望这个网络块学习直接的映射关系H(x),
现在我们让他学习H(x)和输入x之间的残差F(x)。</p>
<p><img alt="" src="../../img/03/04/resblock.jpg" /></p>
<p>其中</p>
<p>
<script type="math/tex; mode=display"> H(x) = F(x) + x </script>
</p>
<p>作者认为这样让网络学习残差映射比原始的、未参考的映射更容易优化。在极端情况下，如果一个恒等映射是最优的，那么将残差置为零比通过一堆非线性层来拟合恒等映射更容易。</p>
<p>将x直接连接到输出的设计被称为 快捷连接（shortcut connection），他可以跨过一层或多层网络简单地执行恒等映射。在实现上既不增加额外的参数也不增加计算复杂度。</p>
<p>发现通过实验可以发现：1）我们极深的残差网络易于优化，但当深度增加时，对应的“简单”网络（简单堆叠层）表现出更高的训练误差；
2）我们的深度残差网络可以从大大增加的深度中轻松获得准确性收益，生成的结果实质上比以前的网络更好。</p>
<p>也就是说训练时候收敛效果更好了，也更快了。测试时候更深的网络性能更好了。</p>
<h2 id="_3">网络结构</h2>
<p>首先作者设计了如下两个网络中使用的模块</p>
<p><img alt="" src="../../img/03/04/resblock2.jpg" /></p>
<p>其中左侧是ResNet-34的构建块，右侧是ResNet-50/101/152的构建块，称作&rdquo;bottleneck&rdquo;。虽然本文包含了两层或者三层，但更多的层也是可以的。不过作者说如果只有一层没有优势。</p>
<p>bottleneck结构就是前面先用1 x 1卷积降维，后面再用1 x 1卷积升维以符合维度大小，这样做可以大大减少计算量。注意bottleneck中3 x 3的卷积层只有一个</p>
<p>通过上面的模块，便可以构建不同层数的网络，构建方式如下：</p>
<p><img alt="" src="../../img/03/04/resnet.jpg" /></p>
<p>其中表哥你第一列的ConvX区分不同阶段（stage），每个阶段之间使用步长为2的卷积来进行下采样。倒数第二层输出的feature map后面是全局平均池化，
也就是每个feature map求平均值获得一维向量，因为ImageNet输出是1000个类别，所以再连接一层1000个神经元的全连接层，最后再接上一个Softmax。</p>
<p>现在有个问题，ResNet50/101/152的的第一个stage的输入channel维度都是64，跨层连接之后维度并不匹配，所以这里不是恒等映射，还会加一个升维的操作。
升维有两种方式：第一种是直接全补0，这样做优势是不会增加网络的参数；第二种是1 x 1卷积升维</p>
<h2 id="_4">代码实现</h2>
<p>基础网络实现如下</p>
<pre><code class="language-python">class BasicBlock(nn.Module):
    &quot;&quot;&quot;Basic Block for resnet 18 and resnet 34

    &quot;&quot;&quot;

    #BasicBlock and BottleNeck block
    #have different output size
    #we use class attribute expansion
    #to distinct
    expansion = 1

    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()

        #residual function
        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels * BasicBlock.expansion)
        )

        #shortcut
        self.shortcut = nn.Sequential()

        #the shortcut output dimension is not the same with residual function
        #use 1*1 convolution to match the dimension
        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * BasicBlock.expansion)
            )

    def forward(self, x):
        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))
</code></pre>
<p>BottleNeck实现如下</p>
<pre><code class="language-python">class BottleNeck(nn.Module):
    &quot;&quot;&quot;Residual block for resnet over 50 layers

    &quot;&quot;&quot;
    expansion = 4
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.residual_function = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels * BottleNeck.expansion),
        )

        self.shortcut = nn.Sequential()

        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=1, bias=False),
                nn.BatchNorm2d(out_channels * BottleNeck.expansion)
            )

    def forward(self, x):
        return nn.ReLU(inplace=True)(self.residual_function(x) + self.shortcut(x))
</code></pre>
<p>网络实现如下</p>
<pre><code class="language-python">class ResNet(nn.Module):

    def __init__(self, block, num_block, num_classes=100):
        super().__init__()

        self.in_channels = 64

        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True))
        #we use a different inputsize than the original paper
        #so conv2_x's stride is 1
        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)
        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)
        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)
        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)
        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

    def _make_layer(self, block, out_channels, num_blocks, stride):
        &quot;&quot;&quot;make resnet layers(by layer i didnt mean this 'layer' was the
        same as a neuron netowork layer, ex. conv layer), one layer may
        contain more than one residual block

        Args:
            block: block type, basic block or bottle neck block
            out_channels: output depth channel number of this layer
            num_blocks: how many blocks per layer
            stride: the stride of the first block of this layer
        Return:
            return a resnet layer
        &quot;&quot;&quot;

        # we have num_block blocks per layer, the first block
        # could be 1 or 2, other blocks would always be 1
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion

        return nn.Sequential(*layers)

    def forward(self, x):
        output = self.conv1(x)
        output = self.conv2_x(output)
        output = self.conv3_x(output)
        output = self.conv4_x(output)
        output = self.conv5_x(output)
        output = self.avg_pool(output)
        output = output.view(output.size(0), -1)
        output = self.fc(output)

        return output


def resnet18():
    &quot;&quot;&quot; return a ResNet 18 object
    &quot;&quot;&quot;
    return ResNet(BasicBlock, [2, 2, 2, 2])

def resnet34():
    &quot;&quot;&quot; return a ResNet 34 object
    &quot;&quot;&quot;
    return ResNet(BasicBlock, [3, 4, 6, 3])

def resnet50():
    &quot;&quot;&quot; return a ResNet 50 object
    &quot;&quot;&quot;
    return ResNet(BottleNeck, [3, 4, 6, 3])

def resnet101():
    &quot;&quot;&quot; return a ResNet 101 object
    &quot;&quot;&quot;
    return ResNet(BottleNeck, [3, 4, 23, 3])

def resnet152():
    &quot;&quot;&quot; return a ResNet 152 object
    &quot;&quot;&quot;
    return ResNet(BottleNeck, [3, 8, 36, 3])
</code></pre>
<p>通过这个代码我们也可以看到使用相同块堆叠设计网络的简易之处，可以很方便的提升网络层数。且代码非常简洁。</p>
<h2 id="_5">讨论</h2>
<p>这部分并非掌握的地方，如果暂时不了解没有关系，可以等之后再来看看。</p>
<p>残差结构为什么有效？</p>
<ul>
<li>自适应深度：网络退化问题就体现了多层网络难以拟合恒等映射这种情况，也就是说H(x)难以拟合x，
但使用了残差结构之后，拟合恒等映射变得很容易，直接把网络参数全学习到为0，只留下那个恒等映射的跨层连接即可。
于是当网络不需要这么深时，中间的恒等映射就可以多一点，反之就可以少一点。</li>
<li>“差分放大器”：假设最优H(x)更接近恒等映射，那么网络更容易发现除恒等映射之外微小的波动</li>
<li>模型集成：整个ResNet类似于多个网络的集成，原因是删除ResNet的部分网络结点不影响整个网络的性能，但VGGNet会崩溃，</li>
<li>缓解梯度消失：针对一个残差结构对输入 x 求导就可以知道，由于跨层连接的存在，总梯度在F(x)对x的导数基础上还会加1</li>
</ul>

<div id="disqus_thread"></div>
<script>
    (function() {
        var d = document, s = d.createElement('script');

        s.src = '//learnopengl-cn.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>请启用JavaScript以浏览<a href="https://disqus.com/?ref_noscript" rel="nofollow">Disqus评论。</a></noscript></div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <center>Powered by <a href="http://www.mkdocs.org/">MkDocs</a> and <a href="http://bootswatch.com/yeti/">Yeti</a></center>
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>var base_url = '../..';</script>
        <script src="../../js/base.js"></script>
        <script src="../../mathjax/MathJax.js?config=TeX-AMS_HTML"></script>
        <script src="../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">关闭</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">搜索</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            请在下面输入你要搜索的文本（仅支持英文）：
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="搜索..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>