<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="我对DNN知识系统整理的一次尝试">
        
        <link rel="canonical" href="https://learnai-cn.github.io/02%20HardWayToDeep/01%201Channel%20minist/">
        <link rel="shortcut icon" href="../../img/favicon.ico">

	<title>minist实现 - LearnAI-CN</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="../../css/style.css" rel="stylesheet">
        <link href="../../css/admonition_fix.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-80323542-1', 'auto');
          ga('send', 'pageview');
        </script>
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="../..">LearnAI-CN</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            
            
                <li >
                    <a href="../..">主页</a>
                </li>
            
            
            
                <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">目录 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        
<li >
    <a href="../../intro/">简介</a>
</li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">入门</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../01%20Getting%20started/01%20Introduction/">深度学习介绍</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/02%20Perceptron/">感知机</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/03%20XOR/">异或操作</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/04%20S%20neural/">s型神经元</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/05%20loss%20functional/">损失函数</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/06%20Backpropagation/">反向传播算法</a>
</li>

        
            
<li >
    <a href="../../01%20Getting%20started/07%20Selflearning%20XOR/">自学习异或操作</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">走向深度</a>
    <ul class="dropdown-menu">
        
            
<li class="active">
    <a href="./">minist实现</a>
</li>

        
            
<li >
    <a href="../02%20Gradient%20vanishing/">梯度消失/爆炸</a>
</li>

        
            
<li >
    <a href="../03%20generalization/">泛化性</a>
</li>

        
            
<li >
    <a href="../04%20overfitting/">过拟合/欠拟合</a>
</li>

        
            
<li >
    <a href="../05%20regulization/">正则化</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">实现minist</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../02%20minist/01%20Convolution/">卷积层</a>
</li>

        
            
<li >
    <a href="../../02%20minist/02%20Pooling/">池化层</a>
</li>

        
            
<li >
    <a href="../../02%20minist/03%20Activation/">激活层</a>
</li>

        
            
<li >
    <a href="../../02%20minist/04%20Fully%20conection/">全连接层</a>
</li>

        
            
<li >
    <a href="../../02%20minist/05%20Optimization%20Algorithm/">优化函数</a>
</li>

        
            
<li >
    <a href="../../02%20minist/06%20Normalization/">归一化层</a>
</li>

        
            
<li >
    <a href="../../02%20minist/07%20LeNet/">再次实现minist</a>
</li>

        
            
<li >
    <a href="../../02%20minist/08%20WhyDCNNUseful/">为什么卷积有效</a>
</li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">深入介绍</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../02%20minist/09%20Deep%20introduce/01%20DNN%20feature/">DNN特性</a>
</li>

        
            
<li >
    <a href="../../02%20minist/09%20Deep%20introduce/02%20pooling%20BP/">池化层反向传播</a>
</li>

        
            
<li >
    <a href="../../02%20minist/09%20Deep%20introduce/03%20Receptive%20Field/">感受野</a>
</li>

        
    </ul>
  </li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">经典神经网络</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../03%20classicial%20model/01%20AlexNet/">AlexNet</a>
</li>

        
            
<li >
    <a href="../../03%20classicial%20model/02%20VGG/">VGG</a>
</li>

        
            
<li >
    <a href="../../03%20classicial%20model/03%20GoogleNet/">GoogLeNet</a>
</li>

        
            
<li >
    <a href="../../03%20classicial%20model/04%20ResNet/">ResNet</a>
</li>

        
            
<li >
    <a href="../../03%20classicial%20model/05%20DenseNet/">DenseNet</a>
</li>

        
            
<li >
    <a href="../../03%20classicial%20model/06%20SENet/">SENet</a>
</li>

        
            
<li >
    <a href="../../03%20classicial%20model/07%20MobileNet/">MoblieNet</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">分割任务</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../04%20Segmentation/01%20Introduction/">介绍与基础</a>
</li>

        
            
<li >
    <a href="../../04%20Segmentation/02%20FCN/">FCN</a>
</li>

        
            
<li >
    <a href="../../04%20Segmentation/03%20UNet/">Unet</a>
</li>

        
            
<li >
    <a href="../../04%20Segmentation/04%20DeepLab%E7%B3%BB%E5%88%97/">DeepLab系列</a>
</li>

        
            
<li >
    <a href="../../04%20Segmentation/05%20DANet/">DANet</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">检测</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../05%20Detection/01%20Introduction/">介绍</a>
</li>

        
            
<li >
    <a href="../../05%20Detection/02%20RCNN/">RCNN</a>
</li>

        
            
<li >
    <a href="../../05%20Detection/03%20Fast%20RCNN/">Fast RCNN</a>
</li>

        
            
<li >
    <a href="../../05%20Detection/04%20Faster%20RCNN/">Faster RCNN</a>
</li>

        
            
<li >
    <a href="../../05%20Detection/05%20YOLOv1/">YOLOv1</a>
</li>

        
            
<li >
    <a href="../../05%20Detection/06%20YOLOv2/">YOLOv2</a>
</li>

        
            
<li >
    <a href="../../05%20Detection/07%20YOLOv3/">YOLOv3</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">Transformer</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../06%20Transformer/01%20Debugging/">Transformer</a>
</li>

        
            
<li >
    <a href="../../06%20Transformer/02%20Text%20Rendering/">ViT</a>
</li>

        
            
<li >
    <a href="../../06%20Transformer/03%20SwinTransformer/">SwinTransformer</a>
</li>

        
            
<li >
    <a href="../../06%20Transformer/04%20DETR/">DETR</a>
</li>

        
            
<li >
    <a href="../../06%20Transformer/05%20TransSeg/">TransFormer分割</a>
</li>

        
            
<li >
    <a href="../../06%20Transformer/06%20CLIP/">CLIP</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">AIGC</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../07%20AIGC/01%20Theory/">理论</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">细分方向</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../08%20Subdivision%20direction/Denoise/01%20Paper%20list/">Denoise</a>
</li>

        
            
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">SuperResolution</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../08%20Subdivision%20direction/SuperResolution/01%20SISR%20Paper%20list/">SISR Paper list</a>
</li>

        
            
<li >
    <a href="../../08%20Subdivision%20direction/SuperResolution/02%20VSR%20Paper%20list/">VSR Paper list</a>
</li>

        
    </ul>
  </li>

        
            
<li >
    <a href="../../08%20Subdivision%20direction/zero%20shot/01%20Paper%20list/">zero shot</a>
</li>

        
    </ul>
  </li>

                    
                        
  <li class="dropdown-submenu">
    <a tabindex="-1" class="nav-title">机器学习</a>
    <ul class="dropdown-menu">
        
            
<li >
    <a href="../../09%20Mechine%20Learning/01%20Theory/">介绍</a>
</li>

        
    </ul>
  </li>

                    
                        
<li >
    <a href="../../legacy/">历史存档</a>
</li>

                    
                    </ul>
                </li>
            
            
            
                <li >
                    <a href="../../code_repo/">代码仓库</a>
                </li>
            
            
            </ul>

            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> 搜索
                    </a>
                </li>
                <li >
                    <a rel="next" href="../../01%20Getting%20started/07%20Selflearning%20XOR/">
                        <i class="fa fa-arrow-left"></i> 上一节
                    </a>
                </li>
                <li >
                    <a rel="prev" href="../02%20Gradient%20vanishing/">
                        下一节 <i class="fa fa-arrow-right"></i>
                    </a>
                </li>
                
                <li>
                    <a href="https://github.com/learnAI-CN/learnAI-code">
                        
                            <i class="fa fa-github"></i>
                        
                        GitHub
                    </a>
                </li>
                
                <li>
                    <a href="/img/self.png">
                            <img class="paypal" src="/img/paypal_logo.png" alt="">
                        关于作者
                    </a>
                </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#minist">Minist基础实现</a></li>
        
            <li><a href="#_1">初始化网络</a></li>
        
            <li><a href="#_2">前向传播</a></li>
        
            <li><a href="#_3">随机梯度下降</a></li>
        
            <li><a href="#_4">更新参数</a></li>
        
            <li><a href="#_5">数据加载</a></li>
        
            <li><a href="#_6">开始训练</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">

<h1 id="minist">Minist基础实现</h1>
<p>回想一下实现异或操作的神经网络，现在我们希望让网络能实现的工程更加复杂一些，比如识别一个数字。</p>
<p>首先，我们展示了一些minist数据。</p>
<p><img alt="" src="../../img/02/01/minist.jpg" /></p>
<p>通过你聪明的大脑你肯定瞬间能认出这些数字，但是如果是计算机呢？如何让他们从存储时候的二进制，经过网络推理得到数字结果。
根据我们之前的工作，我们可以将图像转成一维输入，然后利用多层神经元训练学习，得到最终的10个输出，分别代表0-9的预测结果。
接下来我们就要通过这种思路实现。</p>
<h2 id="_1">初始化网络</h2>
<p>我们定义一个Network类⽤来初始化⼀个Network对象：</p>
<pre><code class="language-python">class Network(object):
    def __init__(self, sizes):
        self.num_layers = len(sizes)
        self.sizes = sizes
        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
        self.weights = [np.random.randn(y, x)
        for x, y in zip(sizes[:-1], sizes[1:])]
</code></pre>
<p>通过</p>
<pre><code class="language-python">net = Network([2, 3, 1])
</code></pre>
<p>便可以实例化一个第⼀层有 2 个神经元，第⼆层有 3 个神经元，最后层有 1 个神经元的 Network 对象。
你可以发现修改初始化时候的list就可以修改网络的层数和每层的神经元数量，这不再用对每一层进行定义。
而np.random.randn 函数本身就是用来⽣成均值为 0，标准差为 1 的⾼斯分布，可以当作参数的初始化。</p>
<h2 id="_2">前向传播</h2>
<p>我们可以通过一个for循环获得前向输入。</p>
<pre><code class="language-python">def feedforward(self, a):
    &quot;&quot;&quot;Return the output of the network if &quot;a&quot; is input.&quot;&quot;&quot;
    for b, w in zip(self.biases, self.weights):
    a = sigmoid(np.dot(w, a)+b)
return a
</code></pre>
<h2 id="_3">随机梯度下降</h2>
<p>现在我们要定义一个随机梯度下降算法让网络学习，</p>
<pre><code class="language-python">def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):
    &quot;&quot;&quot;Train the neural network using mini-batch stochastic
    gradient descent. The &quot;training_data&quot; is a list of tuples
    &quot;(x, y)&quot; representing the training inputs and the desired
    outputs. The other non-optional parameters are
    self-explanatory. If &quot;test_data&quot; is provided then the
    network will be evaluated against the test data after each
    epoch, and partial progress printed out. This is useful for
    tracking progress, but slows things down substantially.&quot;&quot;&quot;
    if test_data: n_test = len(test_data)
    n = len(training_data)
    for j in xrange(epochs):
        random.shuffle(training_data)
        mini_batches = [
            training_data[k:k+mini_batch_size]
            for k in xrange(0, n, mini_batch_size)]
        for mini_batch in mini_batches:
            self.update_mini_batch(mini_batch, eta)
        if test_data:
            print &quot;Epoch {0}: {1} / {2}&quot;.format(
            j, self.evaluate(test_data), n_test)
        else:
            print &quot;Epoch {0} complete&quot;.format(j)
</code></pre>
<p>training_data 是⼀个 (x, y) 元组的列表，表⽰训练输⼊和其对应的期望输出。变量 epochs 和
mini_batch_size 正如你预料的 —— 迭代期数量，和采样时的⼩批量数据的⼤⼩。eta 是学习速率，
η。如果给出了可选参数 test_data，那么程序会在每个训练器后评估⽹络，并打印出部分进展。</p>
<h2 id="_4">更新参数</h2>
<p>在每个迭代期，它⾸先随机地将训练数据打乱，然后将它分成多个适当⼤
⼩的⼩批量数据。这是⼀个简单的从训练数据的随机采样⽅法。然后对于每⼀个 mini_batch
我们应⽤⼀次梯度下降。这是通过代码 self.update_mini_batch(mini_batch, eta) 完成的，它仅
仅使⽤ mini_batch 中的训练数据，根据单次梯度下降的迭代更新⽹络的权重和偏置。</p>
<pre><code class="language-python">    def update_mini_batch(self, mini_batch, eta):
        &quot;&quot;&quot;Update the network's weights and biases by applying
        gradient descent using backpropagation to a single mini batch.
        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``
        is the learning rate.&quot;&quot;&quot;
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        for x, y in mini_batch:
            delta_nabla_b, delta_nabla_w = self.backprop(x, y)
            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
        self.weights = [w-(eta/len(mini_batch))*nw
                        for w, nw in zip(self.weights, nabla_w)]
        self.biases = [b-(eta/len(mini_batch))*nb
                       for b, nb in zip(self.biases, nabla_b)]
</code></pre>
<p>⼤部分⼯作由这⾏代码完成：</p>
<pre><code class="language-python">delta_nabla_b, delta_nabla_w = self.backprop(x, y)
</code></pre>
<p>这⾏调⽤了⼀个称为反向传播的算法，⼀种快速计算代价函数的梯度的⽅法。因此
update_mini_batch 的⼯作仅仅是对 mini_batch 中的每⼀个训练样本计算梯度，然后适当地更
新 self.weights 和 self.biases。</p>
<p>该代码的实现如下</p>
<pre><code class="language-python">    def backprop(self, x, y):
        &quot;&quot;&quot;Return a tuple ``(nabla_b, nabla_w)`` representing the
        gradient for the cost function C_x.  ``nabla_b`` and
        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar
        to ``self.biases`` and ``self.weights``.&quot;&quot;&quot;
        nabla_b = [np.zeros(b.shape) for b in self.biases]
        nabla_w = [np.zeros(w.shape) for w in self.weights]
        # feedforward
        activation = x
        activations = [x] # list to store all the activations, layer by layer
        zs = [] # list to store all the z vectors, layer by layer
        for b, w in zip(self.biases, self.weights):
            z = np.dot(w, activation)+b
            zs.append(z)
            activation = sigmoid(z)
            activations.append(activation)
        # backward pass
        delta = self.cost_derivative(activations[-1], y) * \
            sigmoid_prime(zs[-1])
        nabla_b[-1] = delta
        nabla_w[-1] = np.dot(delta, activations[-2].transpose())
        # Note that the variable l in the loop below is used a little
        # differently to the notation in Chapter 2 of the book.  Here,
        # l = 1 means the last layer of neurons, l = 2 is the
        # second-last layer, and so on.  It's a renumbering of the
        # scheme in the book, used here to take advantage of the fact
        # that Python can use negative indices in lists.
        for l in xrange(2, self.num_layers):
            z = zs[-l]
            sp = sigmoid_prime(z)
            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
            nabla_b[-l] = delta
            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
        return (nabla_b, nabla_w)
</code></pre>
<p>这里我们还需要定义sigmoid_prime，他是sigmoid的导数。</p>
<pre><code class="language-python">def sigmoid_prime(z):
    &quot;&quot;&quot;Derivative of the sigmoid function.&quot;&quot;&quot;
    return sigmoid(z)*(1-sigmoid(z))
</code></pre>
<h2 id="_5">数据加载</h2>
<pre><code class="language-python">
def load_data():
    &quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,
    the validation data, and the test data.

    The ``training_data`` is returned as a tuple with two entries.
    The first entry contains the actual training images.  This is a
    numpy ndarray with 50,000 entries.  Each entry is, in turn, a
    numpy ndarray with 784 values, representing the 28 * 28 = 784
    pixels in a single MNIST image.

    The second entry in the ``training_data`` tuple is a numpy ndarray
    containing 50,000 entries.  Those entries are just the digit
    values (0...9) for the corresponding images contained in the first
    entry of the tuple.

    The ``validation_data`` and ``test_data`` are similar, except
    each contains only 10,000 images.

    This is a nice data format, but for use in neural networks it's
    helpful to modify the format of the ``training_data`` a little.
    That's done in the wrapper function ``load_data_wrapper()``, see
    below.
    &quot;&quot;&quot;
    f = gzip.open('../data/mnist.pkl.gz', 'rb')
    training_data, validation_data, test_data = cPickle.load(f)
    f.close()
    return (training_data, validation_data, test_data)


def load_data_wrapper():
    &quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,
    test_data)``. Based on ``load_data``, but the format is more
    convenient for use in our implementation of neural networks.

    In particular, ``training_data`` is a list containing 50,000
    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray
    containing the input image.  ``y`` is a 10-dimensional
    numpy.ndarray representing the unit vector corresponding to the
    correct digit for ``x``.

    ``validation_data`` and ``test_data`` are lists containing 10,000
    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional
    numpy.ndarry containing the input image, and ``y`` is the
    corresponding classification, i.e., the digit values (integers)
    corresponding to ``x``.

    Obviously, this means we're using slightly different formats for
    the training data and the validation / test data.  These formats
    turn out to be the most convenient for use in our neural network
    code.&quot;&quot;&quot;
    tr_d, va_d, te_d = load_data()
    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]
    training_results = [vectorized_result(y) for y in tr_d[1]]
    training_data = zip(training_inputs, training_results)
    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]
    validation_data = zip(validation_inputs, va_d[1])
    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]
    test_data = zip(test_inputs, te_d[1])
    return (training_data, validation_data, test_data)


def vectorized_result(j):
    &quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth
    position and zeroes elsewhere.  This is used to convert a digit
    (0...9) into a corresponding desired output from the neural
    network.&quot;&quot;&quot;
    e = np.zeros((10, 1))
    e[j] = 1.0
    return e
</code></pre>
<h2 id="_6">开始训练</h2>
<p>定义主函数运行代码,使⽤随机梯度下降来从 MNIST training_data 学习超过 30 次迭代期，⼩批量数
据⼤⼩为 10，学习速率 η = 3.0，</p>
<pre><code class="language-python">if __name__==&quot;__main__&quot;:
    net = network.Network([784, 30, 10]) 

    net.SGD(training_data, 30, 10, 3.0, test_data=test_data)

</code></pre>
<p>经过训练可以得到以下的输出</p>
<pre><code class="language-python">Epoch 28: 9542 / 10000
Epoch 29: 9534 / 10000
</code></pre>
<p>说明我们的结果达到了95%。</p>

<div id="disqus_thread"></div>
<script>
    (function() {
        var d = document, s = d.createElement('script');

        s.src = '//learnopengl-cn.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>请启用JavaScript以浏览<a href="https://disqus.com/?ref_noscript" rel="nofollow">Disqus评论。</a></noscript></div>
        </div>

        <footer class="col-md-12">
            <hr>
            
            <center>Powered by <a href="http://www.mkdocs.org/">MkDocs</a> and <a href="http://bootswatch.com/yeti/">Yeti</a></center>
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script>var base_url = '../..';</script>
        <script src="../../js/base.js"></script>
        <script src="../../mathjax/MathJax.js?config=TeX-AMS_HTML"></script>
        <script src="../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">关闭</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">搜索</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            请在下面输入你要搜索的文本（仅支持英文）：
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="搜索..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>
    </body>
</html>